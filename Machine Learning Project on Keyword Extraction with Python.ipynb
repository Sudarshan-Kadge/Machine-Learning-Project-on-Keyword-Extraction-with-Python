{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Project on Keyword Extraction with Python\n",
    "Now, in this section, I will take you through a Machine Learning project on Keyword Extraction with Python programming language. I will start by importing the necessary libraries and the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"papers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>event_type</th>\n",
       "      <th>pdf_name</th>\n",
       "      <th>abstract</th>\n",
       "      <th>paper_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1987</td>\n",
       "      <td>Self-Organization of Associative Database and ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1-self-organization-of-associative-database-an...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>1987</td>\n",
       "      <td>A Mean Field Theory of Layer IV of Visual Cort...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10-a-mean-field-theory-of-layer-iv-of-visual-c...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>1988</td>\n",
       "      <td>Storing Covariance by the Associative Long-Ter...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100-storing-covariance-by-the-associative-long...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>1994</td>\n",
       "      <td>Bayesian Query Construction for Neural Network...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000-bayesian-query-construction-for-neural-ne...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Bayesian Query Construction for Neural\\nNetwor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001</td>\n",
       "      <td>1994</td>\n",
       "      <td>Neural Network Ensembles, Cross Validation, an...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1001-neural-network-ensembles-cross-validation...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Neural Network Ensembles, Cross\\nValidation, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1002</td>\n",
       "      <td>1994</td>\n",
       "      <td>Using a neural net to instantiate a deformable...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1002-using-a-neural-net-to-instantiate-a-defor...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>U sing a neural net to instantiate a\\ndeformab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1003</td>\n",
       "      <td>1994</td>\n",
       "      <td>Plasticity-Mediated Competitive Learning</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1003-plasticity-mediated-competitive-learning.pdf</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Plasticity-Mediated Competitive Learning\\n\\nTe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1004</td>\n",
       "      <td>1994</td>\n",
       "      <td>ICEG Morphology Classification using an Analog...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1004-iceg-morphology-classification-using-an-a...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>ICEG Morphology Classification using an\\nAnalo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1005</td>\n",
       "      <td>1994</td>\n",
       "      <td>Real-Time Control of a Tokamak Plasma Using Ne...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1005-real-time-control-of-a-tokamak-plasma-usi...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Real-Time Control of a Tokamak Plasma\\nUsing N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1006</td>\n",
       "      <td>1994</td>\n",
       "      <td>Pulsestream Synapses with Non-Volatile Analogu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1006-pulsestream-synapses-with-non-volatile-an...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Real-Time Control of a Tokamak Plasma\\nUsing N...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  year                                              title event_type  \\\n",
       "0     1  1987  Self-Organization of Associative Database and ...        NaN   \n",
       "1    10  1987  A Mean Field Theory of Layer IV of Visual Cort...        NaN   \n",
       "2   100  1988  Storing Covariance by the Associative Long-Ter...        NaN   \n",
       "3  1000  1994  Bayesian Query Construction for Neural Network...        NaN   \n",
       "4  1001  1994  Neural Network Ensembles, Cross Validation, an...        NaN   \n",
       "5  1002  1994  Using a neural net to instantiate a deformable...        NaN   \n",
       "6  1003  1994           Plasticity-Mediated Competitive Learning        NaN   \n",
       "7  1004  1994  ICEG Morphology Classification using an Analog...        NaN   \n",
       "8  1005  1994  Real-Time Control of a Tokamak Plasma Using Ne...        NaN   \n",
       "9  1006  1994  Pulsestream Synapses with Non-Volatile Analogu...        NaN   \n",
       "\n",
       "                                            pdf_name          abstract  \\\n",
       "0  1-self-organization-of-associative-database-an...  Abstract Missing   \n",
       "1  10-a-mean-field-theory-of-layer-iv-of-visual-c...  Abstract Missing   \n",
       "2  100-storing-covariance-by-the-associative-long...  Abstract Missing   \n",
       "3  1000-bayesian-query-construction-for-neural-ne...  Abstract Missing   \n",
       "4  1001-neural-network-ensembles-cross-validation...  Abstract Missing   \n",
       "5  1002-using-a-neural-net-to-instantiate-a-defor...  Abstract Missing   \n",
       "6  1003-plasticity-mediated-competitive-learning.pdf  Abstract Missing   \n",
       "7  1004-iceg-morphology-classification-using-an-a...  Abstract Missing   \n",
       "8  1005-real-time-control-of-a-tokamak-plasma-usi...  Abstract Missing   \n",
       "9  1006-pulsestream-synapses-with-non-volatile-an...  Abstract Missing   \n",
       "\n",
       "                                          paper_text  \n",
       "0  767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...  \n",
       "1  683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...  \n",
       "2  394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...  \n",
       "3  Bayesian Query Construction for Neural\\nNetwor...  \n",
       "4  Neural Network Ensembles, Cross\\nValidation, a...  \n",
       "5  U sing a neural net to instantiate a\\ndeformab...  \n",
       "6  Plasticity-Mediated Competitive Learning\\n\\nTe...  \n",
       "7  ICEG Morphology Classification using an\\nAnalo...  \n",
       "8  Real-Time Control of a Tokamak Plasma\\nUsing N...  \n",
       "9  Real-Time Control of a Tokamak Plasma\\nUsing N...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7241, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7241 entries, 0 to 7240\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   id          7241 non-null   int64 \n",
      " 1   year        7241 non-null   int64 \n",
      " 2   title       7241 non-null   object\n",
      " 3   event_type  2422 non-null   object\n",
      " 4   pdf_name    7241 non-null   object\n",
      " 5   abstract    7241 non-null   object\n",
      " 6   paper_text  7241 non-null   object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 396.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains 7 columns: id, year, title, even_type, pdf_name, abstract and paper_text. We are mainly interested in the paper_text which includes both the title and the abstract."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The next step is to preprocess our textual data. For this task, I will use the NLTK library in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Sudarshan\n",
      "[nltk_data]     Kadge\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "# Lets create a custom list of stop words\n",
    "new_words = [\"fig\", \"figure\", \"image\", \"sample\", \"using\",\n",
    "            \"show\", \"result\", \"large\",\n",
    "             \"also\", \"one\", \"two\", \"three\",\n",
    "            \"four\", \"five\", \"seven\", \"eight\", \"nine\"]\n",
    "stop_words = list(stop_words.union(new_words))\n",
    "\n",
    "def pre_process(text):\n",
    "    #lowercase\n",
    "    text=text.lower()\n",
    "    #remove tags\n",
    "    text=re.sub(\"&lt;/%.*?&gt\", \"&lt;&gt;\", text)\n",
    "    #remove special characters and digits\n",
    "    text = re.sub(\"(\\\\d|\\\\W)+\", \" \", text)\n",
    "    # convert to list from string\n",
    "    text = text.split()\n",
    "    #remove stopwords\n",
    "    text = [word for word in text if len(word)>=3]\n",
    "    #lemmatize\n",
    "    lmtzr=WordNetLemmatizer()\n",
    "    text = [lmtzr.lemmatize(word) for word in text]\n",
    "    return \" \".join(text)\n",
    "docs = df['paper_text'].apply(lambda x:pre_process(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using TF-IDF\n",
    "TF-IDF stands for Text Frequency Inverse Document Frequency. The importance of each word increases in proportion to the number of times a word appears in the document (Text Frequency – TF) but is offset by the frequency of the word in the corpus (Inverse Document Frequency – IDF).\n",
    "\n",
    "Using the tf-idf weighting scheme, the keywords are the words with the highest TF-IDF score. For this task, I’ll first use the CountVectorizer method in Scikit-learn to create a vocabulary and generate the word count:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#create a vocabulary of words\n",
    "cv = CountVectorizer(max_df=0.95, #ignore words that appears 95% of documents\n",
    "                    max_features=10000, #The size of the vocabulary\n",
    "                    ngram_range=(1,3) #Vocabulary contains single words , bigrams, trigrams\n",
    "                    )\n",
    "word_count_vector=cv.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now I’m going to use the TfidfTransformer in Scikit-learn to calculate the reverse frequency of documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfTransformer()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer(smooth_idf=True, use_idf=True)\n",
    "tfidf_transformer.fit(word_count_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we are ready for the final step. In this step, I will create a function for the task of Keyword Extraction with Python by using the Tf-IDF vectorization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====Title=====\n",
      "Algorithms for Non-negative Matrix Factorization\n",
      "\n",
      "=====Abstract=====\n",
      "Non-negative matrix factorization (NMF) has previously been shown to \r\n",
      "be a useful decomposition for multivariate data. Two different multi- \r\n",
      "plicative algorithms for NMF are analyzed. They differ only slightly in \r\n",
      "the multiplicative factor used in the update rules. One algorithm can be \r\n",
      "shown to minimize the conventional least squares error while the other \r\n",
      "minimizes the generalized Kullback-Leibler divergence. The monotonic \r\n",
      "convergence of both algorithms can be proven using an auxiliary func- \r\n",
      "tion analogous to that used for proving convergence of the Expectation- \r\n",
      "Maximization algorithm. The algorithms can also be interpreted as diag- \r\n",
      "onally rescaled gradient descent, where the rescaling factor is optimally \r\n",
      "chosen to ensure convergence. \n",
      "\n",
      "===Keywords===\n",
      "update rule 0.338\n",
      "update 0.279\n",
      "the update 0.248\n",
      "auxiliary 0.207\n",
      "rule 0.188\n",
      "nmf 0.179\n",
      "multiplicative 0.172\n",
      "matrix factorization 0.16\n",
      "matrix 0.16\n",
      "factorization 0.147\n"
     ]
    }
   ],
   "source": [
    "def sort_coo(coo_matrix):\n",
    "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
    "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)   \n",
    "\n",
    "def extract_topn_from_vector(feature_names, sorted_items, topn=10):\n",
    "    \"\"\"get the feature names and tf-idf score of top n items\"\"\"\n",
    "    \n",
    "    #use only topn items from vector\n",
    "    sorted_items = sorted_items[:topn]\n",
    "\n",
    "    score_vals = []\n",
    "    feature_vals = []\n",
    "\n",
    "    for idx, score in sorted_items:\n",
    "        fname = feature_names[idx]\n",
    "        \n",
    "        #keep track of feature name and its corresponding score\n",
    "        score_vals.append(round(score, 3))\n",
    "        feature_vals.append(feature_names[idx])\n",
    "\n",
    "    #create a tuples of feature,score\n",
    "    #results = zip(feature_vals,score_vals)\n",
    "    results= {}\n",
    "    for idx in range(len(feature_vals)):\n",
    "        results[feature_vals[idx]]=score_vals[idx]\n",
    "    \n",
    "    return results\n",
    "\n",
    "# get feature names\n",
    "feature_names=cv.get_feature_names()\n",
    "\n",
    "def get_keywords(idx, docs):\n",
    "\n",
    "    #generate tf-idf for the given document\n",
    "    tf_idf_vector=tfidf_transformer.transform(cv.transform([docs[idx]]))\n",
    "\n",
    "    #sort the tf-idf vectors by descending order of scores\n",
    "    sorted_items=sort_coo(tf_idf_vector.tocoo())\n",
    "\n",
    "    #extract only the top n; n here is 10\n",
    "    keywords=extract_topn_from_vector(feature_names,sorted_items,10)\n",
    "    \n",
    "    return keywords\n",
    "\n",
    "def print_results(idx,keywords, df):\n",
    "    # now print the results\n",
    "    print(\"\\n=====Title=====\")\n",
    "    print(df['title'][idx])\n",
    "    print(\"\\n=====Abstract=====\")\n",
    "    print(df['abstract'][idx])\n",
    "    print(\"\\n===Keywords===\")\n",
    "    for k in keywords:\n",
    "        print(k,keywords[k])\n",
    "idx=941\n",
    "keywords=get_keywords(idx, docs)\n",
    "print_results(idx,keywords, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
